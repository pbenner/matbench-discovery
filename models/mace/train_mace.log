The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2023-09-11 09:11:36.122 INFO: MACE version: 0.1.0
2023-09-11 09:11:36.122 INFO: Configuration: Namespace(name='MACE_MPtrj_2022.9', seed=42, log_dir='data-train-result/logs', model_dir='data-train-result', checkpoints_dir='data-train-result/checkpoints', results_dir='data-train-result/results', downloads_dir='data-train-result/downloads', default_dtype='float64', log_level='INFO', error_table='PerAtomMAE', model='ScaleShiftMACE', r_max=5.0, num_radial_basis=8, num_cutoff_basis=5, interaction='RealAgnosticResidualInteractionBlock', interaction_first='RealAgnosticResidualInteractionBlock', max_ell=3, correlation=3, num_interactions=2, MLP_irreps='16x0e', hidden_irreps='32x0e', num_channels=256, max_L=1, gate='silu', scaling='rms_forces_scaling', avg_num_neighbors=1, compute_avg_num_neighbors=True, compute_stress=True, compute_forces=True, train_file='./data-train-preprocessed/train.h5', valid_file='./data-train-preprocessed/valid.h5', valid_fraction=0.1, test_file=None, test_dir=None, num_workers=8, pin_memory=True, atomic_numbers=None, mean=None, std=None, statistics_file='./data-train-preprocessed/statistics.json', E0s=None, energy_key='energy', forces_key='forces', virials_key='virials', stress_key='stress', dipole_key='dipole', charges_key='charges', loss='weighted', forces_weight=1.0, swa_forces_weight=1.0, energy_weight=1.0, swa_energy_weight=1000.0, virials_weight=1.0, swa_virials_weight=10.0, stress_weight=0.5, swa_stress_weight=10.0, dipole_weight=1.0, swa_dipole_weight=1.0, config_type_weights='{"Default":1.0}', optimizer='adam', batch_size=32, valid_batch_size=32, lr=0.01, swa_lr=0.001, weight_decay=5e-07, amsgrad=True, scheduler='ReduceLROnPlateau', lr_factor=0.8, scheduler_patience=50, lr_scheduler_gamma=0.9993, swa=False, start_swa=None, ema=True, ema_decay=0.99, max_num_epochs=100, patience=2048, eval_interval=2, keep_checkpoints=False, restart_latest=False, save_cpu=False, clip_grad=10.0, wandb=False, wandb_project='', wandb_entity='', wandb_name='', wandb_log_hypers=['num_channels', 'max_L', 'correlation', 'lr', 'swa_lr', 'weight_decay', 'batch_size', 'max_num_epochs', 'start_swa', 'energy_weight', 'forces_weight'])
2023-09-11 09:11:36.123 INFO: Using statistics json file
2023-09-11 09:11:36.123 INFO: Using atomic numbers from statistics file
2023-09-11 09:11:36.123 INFO: AtomicNumberTable: (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 89, 90, 91, 92, 93, 94)
2023-09-11 09:11:36.123 INFO: Atomic Energies not in training file, using command line argument E0s
2023-09-11 09:11:36.124 INFO: Atomic energies: [-3.6673775936325184, -1.321978574671279, -3.47815910592578, -4.724966512505185, -7.727941403300326, -8.404543836565129, -7.359429774977432, -7.284436081345614, -4.896162007436489, -0.03005797428312995, -2.7527187727369, -2.8138258116559136, -4.844369939040846, -7.6966307568316115, -6.96321292174237, -4.673811566998673, -2.813984104722163, -0.06233472731112788, -2.6251773081704863, -5.384791381758609, -7.916197568907359, -10.270820955634214, -8.672390387555845, -9.2371580345617, -8.305620224433062, -7.054671703876374, -5.570915377375696, -5.174147851464132, -3.251035550574451, -1.2879654275024013, -3.5321835252059812, -4.711328365973749, -3.9717755452456673, -3.886221455984922, -2.5183143168985502, 6.706842222672468, -2.566057480857263, -4.938993788294903, -10.153603816562159, -11.857062150232505, -12.14164656151253, -8.786094380920531, -8.795434431218645, -7.778351502991773, -6.838726494373795, -4.881216430056056, -2.0605586704343675, -0.6439905162993389, -2.788575343692543, -3.816810475940441, -3.587983770584603, -2.8805917608627976, -1.6360524330360255, 9.796001071919388, -2.7486371263604354, -4.986670776340143, -8.929476698318382, -8.74170685282431, -8.01217127881877, -8.233598378021814, -7.62454389634746, -8.161368139142393, -13.591451290378114, -18.538136714242995, -7.644552511106582, -8.115049752450005, -7.614570319217799, -6.82962645334957, -7.820026786949461, -3.5770491745130024, -7.469205400904766, -12.770648602823787, -14.110986902146283, -9.354405708044254, -11.376459286198285, -9.611613368883013, -7.321263077561875, -5.304305597659051, -2.3873175082519373, 0.24792131307789267, -2.31553585581406, -3.7254481655069127, -3.4301772252097935, -5.065907805804548, -11.017529306980132, -12.244262478240024, -13.846602972246156, -14.952721865054968, -15.303292182007306]
2023-09-11 09:11:36.168 INFO: WeightedEnergyForcesLoss(energy_weight=1.000, forces_weight=1.000)
2023-09-11 09:11:36.168 INFO: Average number of neighbors: 25.57754135131836
2023-09-11 09:11:36.168 INFO: Selected the following outputs: {'energy': True, 'forces': True, 'virials': False, 'stress': True, 'dipoles': False}
2023-09-11 09:11:36.168 INFO: Building model
2023-09-11 09:11:36.168 INFO: Hidden irreps: 256x0e + 256x1o
/home/pbenner/.local/opt/anaconda3/envs/mace/lib/python3.10/site-packages/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn("The TorchScript type system doesn't support "
/home/pbenner/.local/opt/anaconda3/envs/mace/lib/python3.10/site-packages/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn("The TorchScript type system doesn't support "
/home/pbenner/.local/opt/anaconda3/envs/mace/lib/python3.10/site-packages/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn("The TorchScript type system doesn't support "
/home/pbenner/.local/opt/anaconda3/envs/mace/lib/python3.10/site-packages/torch/jit/_check.py:172: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.
  warnings.warn("The TorchScript type system doesn't support "
2023-09-11 09:11:39.796 INFO: DistributedDataParallel(
  (module): ScaleShiftMACE(
    (node_embedding): LinearNodeEmbeddingBlock(
      (linear): Linear(89x0e -> 256x0e | 22784 weights)
    )
    (radial_embedding): RadialEmbeddingBlock(
      (bessel_fn): BesselBasis(r_max=4.5, num_basis=8, trainable=False)
      (cutoff_fn): PolynomialCutoff(p=5.0, r_max=4.5)
    )
    (spherical_harmonics): SphericalHarmonics()
    (atomic_energies_fn): AtomicEnergiesBlock(energies=[-3.6674, -1.3220, -3.4782, -4.7250, -7.7279, -8.4045, -7.3594, -7.2844, -4.8962, -0.0301, -2.7527, -2.8138, -4.8444, -7.6966, -6.9632, -4.6738, -2.8140, -0.0623, -2.6252, -5.3848, -7.9162, -10.2708, -8.6724, -9.2372, -8.3056, -7.0547, -5.5709, -5.1741, -3.2510, -1.2880, -3.5322, -4.7113, -3.9718, -3.8862, -2.5183, 6.7068, -2.5661, -4.9390, -10.1536, -11.8571, -12.1416, -8.7861, -8.7954, -7.7784, -6.8387, -4.8812, -2.0606, -0.6440, -2.7886, -3.8168, -3.5880, -2.8806, -1.6361, 9.7960, -2.7486, -4.9867, -8.9295, -8.7417, -8.0122, -8.2336, -7.6245, -8.1614, -13.5915, -18.5381, -7.6446, -8.1150, -7.6146, -6.8296, -7.8200, -3.5770, -7.4692, -12.7706, -14.1110, -9.3544, -11.3765, -9.6116, -7.3213, -5.3043, -2.3873, 0.2479, -2.3155, -3.7254, -3.4302, -5.0659, -11.0175, -12.2443, -13.8466, -14.9527, -15.3033])
    (interactions): ModuleList(
      (0): RealAgnosticResidualInteractionBlock(
        (linear_up): Linear(256x0e -> 256x0e | 65536 weights)
        (conv_tp): TensorProduct(256x0e x 1x0e+1x1o+1x2e+1x3o -> 256x0e+256x1o+256x2e+256x3o | 1024 paths | 1024 weights)
        (conv_tp_weights): FullyConnectedNet[8, 64, 64, 64, 1024]
        (linear): Linear(256x0e+256x1o+256x2e+256x3o -> 256x0e+256x1o+256x2e+256x3o | 262144 weights)
        (skip_tp): FullyConnectedTensorProduct(256x0e x 89x0e -> 256x0e+256x1o | 5832704 paths | 5832704 weights)
        (reshape): reshape_irreps()
      )
      (1): RealAgnosticResidualInteractionBlock(
        (linear_up): Linear(256x0e+256x1o -> 256x0e+256x1o | 131072 weights)
        (conv_tp): TensorProduct(256x0e+256x1o x 1x0e+1x1o+1x2e+1x3o -> 512x0e+768x1o+768x2e+512x3o | 2560 paths | 2560 weights)
        (conv_tp_weights): FullyConnectedNet[8, 64, 64, 64, 2560]
        (linear): Linear(512x0e+768x1o+768x2e+512x3o -> 256x0e+256x1o+256x2e+256x3o | 655360 weights)
        (skip_tp): FullyConnectedTensorProduct(256x0e+256x1o x 89x0e -> 256x0e | 5832704 paths | 5832704 weights)
        (reshape): reshape_irreps()
      )
    )
    (products): ModuleList(
      (0): EquivariantProductBasisBlock(
        (symmetric_contractions): SymmetricContraction(
          (contractions): ModuleList(
            (0): Contraction(
              (contractions_weighting): ModuleList(
                (0-1): 2 x GraphModule()
              )
              (contractions_features): ModuleList(
                (0-1): 2 x GraphModule()
              )
              (weights): ParameterList(
                  (0): Parameter containing: [torch.float64 of size 89x4x256 (GPU 0)]
                  (1): Parameter containing: [torch.float64 of size 89x1x256 (GPU 0)]
              )
              (graph_opt_main): GraphModule()
            )
            (1): Contraction(
              (contractions_weighting): ModuleList(
                (0-1): 2 x GraphModule()
              )
              (contractions_features): ModuleList(
                (0-1): 2 x GraphModule()
              )
              (weights): ParameterList(
                  (0): Parameter containing: [torch.float64 of size 89x6x256 (GPU 0)]
                  (1): Parameter containing: [torch.float64 of size 89x1x256 (GPU 0)]
              )
              (graph_opt_main): GraphModule()
            )
          )
        )
        (linear): Linear(256x0e+256x1o -> 256x0e+256x1o | 131072 weights)
      )
      (1): EquivariantProductBasisBlock(
        (symmetric_contractions): SymmetricContraction(
          (contractions): ModuleList(
            (0): Contraction(
              (contractions_weighting): ModuleList(
                (0-1): 2 x GraphModule()
              )
              (contractions_features): ModuleList(
                (0-1): 2 x GraphModule()
              )
              (weights): ParameterList(
                  (0): Parameter containing: [torch.float64 of size 89x4x256 (GPU 0)]
                  (1): Parameter containing: [torch.float64 of size 89x1x256 (GPU 0)]
              )
              (graph_opt_main): GraphModule()
            )
          )
        )
        (linear): Linear(256x0e -> 256x0e | 65536 weights)
      )
    )
    (readouts): ModuleList(
      (0): LinearReadoutBlock(
        (linear): Linear(256x0e+256x1o -> 1x0e | 256 weights)
      )
      (1): NonLinearReadoutBlock(
        (linear_1): Linear(256x0e -> 16x0e | 4096 weights)
        (non_linearity): Activation [x] (16x0e -> 16x0e)
        (linear_2): Linear(16x0e -> 1x0e | 16 weights)
      )
    )
    (scale_shift): ScaleShiftBlock(scale=0.804340, shift=0.164779)
  )
)
2023-09-11 09:11:39.800 INFO: Number of parameters: 15847440
2023-09-11 09:11:39.801 INFO: Optimizer: AcceleratedOptimizer (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    name: embedding
    weight_decay: 0.0

Parameter Group 1
    amsgrad: True
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    name: interactions_decay
    weight_decay: 5e-07

Parameter Group 2
    amsgrad: True
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    name: interactions_no_decay
    weight_decay: 0.0

Parameter Group 3
    amsgrad: True
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    name: products
    weight_decay: 5e-07

Parameter Group 4
    amsgrad: True
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    name: readouts
    weight_decay: 0.0
)
2023-09-11 09:11:39.801 INFO: Using gradient clipping with tolerance=10.000
2023-09-11 09:11:39.801 INFO: Started training
2023-09-11 09:11:41.883 INFO: Reducer buckets have been rebuilt in this iteration.
2023-09-11 09:11:41.884 INFO: Reducer buckets have been rebuilt in this iteration.
2023-09-11 09:11:41.884 INFO: Reducer buckets have been rebuilt in this iteration.
2023-09-11 09:11:41.884 INFO: Reducer buckets have been rebuilt in this iteration.
2023-09-11 11:18:51.667 INFO: Epoch 0: loss=0.0071, MAE_E_per_atom=91.0 meV, MAE_F=154.7 meV / A
2023-09-11 11:18:51.668 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-0
2023-09-11 11:18:51.804 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-0/pytorch_model.bin
2023-09-11 11:18:52.173 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-0/optimizer.bin
2023-09-11 11:18:52.176 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-0/random_states_0.pkl
2023-09-11 15:25:16.056 INFO: Epoch 2: loss=0.0058, MAE_E_per_atom=61.3 meV, MAE_F=116.7 meV / A
2023-09-11 15:25:16.089 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-2
2023-09-11 15:25:16.216 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-2/pytorch_model.bin
2023-09-11 15:25:16.562 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-2/optimizer.bin
2023-09-11 15:25:16.563 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-2/random_states_0.pkl
2023-09-11 19:31:18.498 INFO: Epoch 4: loss=0.0044, MAE_E_per_atom=54.7 meV, MAE_F=108.9 meV / A
2023-09-11 19:31:18.555 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-4
2023-09-11 19:31:18.760 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-4/pytorch_model.bin
2023-09-11 19:31:19.174 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-4/optimizer.bin
2023-09-11 19:31:19.175 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-4/random_states_0.pkl
2023-09-11 23:37:16.975 INFO: Epoch 6: loss=0.0035, MAE_E_per_atom=48.9 meV, MAE_F=101.4 meV / A
2023-09-11 23:37:17.022 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-6
2023-09-11 23:37:17.220 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-6/pytorch_model.bin
2023-09-11 23:37:17.680 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-6/optimizer.bin
2023-09-11 23:37:17.681 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-6/random_states_0.pkl
2023-09-12 03:43:47.451 INFO: Epoch 8: loss=0.0037, MAE_E_per_atom=47.6 meV, MAE_F=99.4 meV / A
2023-09-12 07:50:24.267 INFO: Epoch 10: loss=0.0035, MAE_E_per_atom=44.3 meV, MAE_F=94.7 meV / A
2023-09-12 11:57:44.826 INFO: Epoch 12: loss=0.0035, MAE_E_per_atom=47.0 meV, MAE_F=100.7 meV / A
2023-09-12 16:06:41.366 INFO: Epoch 14: loss=0.0027, MAE_E_per_atom=43.9 meV, MAE_F=95.3 meV / A
2023-09-12 16:06:41.405 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-14
2023-09-12 16:06:41.551 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-14/pytorch_model.bin
2023-09-12 16:06:41.944 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-14/optimizer.bin
2023-09-12 16:06:41.945 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-14/random_states_0.pkl
2023-09-12 20:19:02.908 INFO: Epoch 16: loss=0.0021, MAE_E_per_atom=42.1 meV, MAE_F=91.3 meV / A
2023-09-12 20:19:02.947 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-16
2023-09-12 20:19:03.074 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-16/pytorch_model.bin
2023-09-12 20:19:03.411 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-16/optimizer.bin
2023-09-12 20:19:03.412 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-16/random_states_0.pkl
2023-09-13 00:35:35.064 INFO: Epoch 18: loss=0.0025, MAE_E_per_atom=42.2 meV, MAE_F=92.4 meV / A
2023-09-13 04:54:17.373 INFO: Epoch 20: loss=0.0030, MAE_E_per_atom=40.7 meV, MAE_F=89.5 meV / A
2023-09-13 09:18:42.863 INFO: Epoch 22: loss=0.0029, MAE_E_per_atom=39.4 meV, MAE_F=86.8 meV / A
2023-09-13 13:47:32.199 INFO: Epoch 24: loss=0.0035, MAE_E_per_atom=40.7 meV, MAE_F=89.0 meV / A
2023-09-13 18:24:54.835 INFO: Epoch 26: loss=0.0031, MAE_E_per_atom=38.3 meV, MAE_F=85.6 meV / A
2023-09-13 23:07:53.844 INFO: Epoch 28: loss=0.0023, MAE_E_per_atom=38.3 meV, MAE_F=85.4 meV / A
2023-09-14 04:02:16.050 INFO: Epoch 30: loss=0.0021, MAE_E_per_atom=38.3 meV, MAE_F=84.4 meV / A
2023-09-14 04:02:16.096 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-30
2023-09-14 04:02:16.243 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-30/pytorch_model.bin
2023-09-14 04:02:16.608 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-30/optimizer.bin
2023-09-14 04:02:16.609 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-30/random_states_0.pkl
2023-09-14 09:00:28.747 INFO: Epoch 32: loss=0.0021, MAE_E_per_atom=39.6 meV, MAE_F=86.4 meV / A
2023-09-14 14:20:05.907 INFO: Epoch 34: loss=0.0021, MAE_E_per_atom=36.5 meV, MAE_F=83.2 meV / A
2023-09-14 20:02:35.859 INFO: Epoch 36: loss=0.0019, MAE_E_per_atom=36.2 meV, MAE_F=81.6 meV / A
2023-09-14 20:02:35.897 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-36
2023-09-14 20:02:36.019 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-36/pytorch_model.bin
2023-09-14 20:02:36.352 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-36/optimizer.bin
2023-09-14 20:02:36.354 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-36/random_states_0.pkl
2023-09-15 01:45:01.228 INFO: Epoch 38: loss=0.0021, MAE_E_per_atom=36.3 meV, MAE_F=82.5 meV / A
2023-09-15 07:36:44.741 INFO: Epoch 40: loss=0.0026, MAE_E_per_atom=36.0 meV, MAE_F=81.8 meV / A
2023-09-15 13:33:46.272 INFO: Epoch 42: loss=0.0017, MAE_E_per_atom=36.2 meV, MAE_F=81.4 meV / A
2023-09-15 13:33:46.307 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-42
2023-09-15 13:33:46.431 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-42/pytorch_model.bin
2023-09-15 13:33:46.765 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-42/optimizer.bin
2023-09-15 13:33:46.766 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-42/random_states_0.pkl
2023-09-15 19:41:41.585 INFO: Epoch 44: loss=0.0022, MAE_E_per_atom=36.5 meV, MAE_F=82.9 meV / A
2023-09-16 01:59:44.862 INFO: Epoch 46: loss=0.0019, MAE_E_per_atom=34.9 meV, MAE_F=79.8 meV / A
2023-09-16 08:17:10.161 INFO: Epoch 48: loss=0.0025, MAE_E_per_atom=35.4 meV, MAE_F=81.0 meV / A
2023-09-16 14:55:31.710 INFO: Epoch 50: loss=0.0023, MAE_E_per_atom=34.4 meV, MAE_F=79.2 meV / A
2023-09-16 21:42:55.749 INFO: Epoch 52: loss=0.0019, MAE_E_per_atom=35.0 meV, MAE_F=79.7 meV / A
2023-09-17 04:41:59.102 INFO: Epoch 54: loss=0.0024, MAE_E_per_atom=33.6 meV, MAE_F=78.1 meV / A
2023-09-17 11:46:01.221 INFO: Epoch 56: loss=0.0018, MAE_E_per_atom=33.9 meV, MAE_F=77.7 meV / A
2023-09-17 19:03:53.123 INFO: Epoch 58: loss=0.0016, MAE_E_per_atom=35.6 meV, MAE_F=82.5 meV / A
2023-09-17 19:03:53.154 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-58
2023-09-17 19:03:53.279 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-58/pytorch_model.bin
2023-09-17 19:03:53.612 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-58/optimizer.bin
2023-09-17 19:03:53.613 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-58/random_states_0.pkl
2023-09-18 02:30:15.278 INFO: Epoch 60: loss=0.0017, MAE_E_per_atom=34.2 meV, MAE_F=78.5 meV / A
2023-09-18 09:57:37.246 INFO: Epoch 62: loss=0.0017, MAE_E_per_atom=33.1 meV, MAE_F=77.4 meV / A
2023-09-18 19:24:50.782 INFO: Epoch 58: loss=0.0016, MAE_E_per_atom=33.4 meV, MAE_F=78.3 meV / A
2023-09-18 19:24:50.784 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-58
2023-09-18 19:24:51.032 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-58/pytorch_model.bin
2023-09-18 19:24:51.563 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-58/optimizer.bin
2023-09-18 19:24:51.567 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-58/random_states_0.pkl
2023-09-18 23:30:06.010 INFO: Epoch 60: loss=0.0018, MAE_E_per_atom=33.8 meV, MAE_F=78.0 meV / A
2023-09-19 03:35:20.749 INFO: Epoch 62: loss=0.0017, MAE_E_per_atom=33.2 meV, MAE_F=76.4 meV / A
2023-09-19 07:40:42.201 INFO: Epoch 64: loss=0.0017, MAE_E_per_atom=35.2 meV, MAE_F=80.4 meV / A
2023-09-19 11:46:03.057 INFO: Epoch 66: loss=0.0017, MAE_E_per_atom=32.9 meV, MAE_F=76.6 meV / A
2023-09-19 15:51:35.475 INFO: Epoch 68: loss=0.0019, MAE_E_per_atom=32.4 meV, MAE_F=75.5 meV / A
2023-09-19 19:57:41.950 INFO: Epoch 70: loss=0.0016, MAE_E_per_atom=32.9 meV, MAE_F=75.9 meV / A
2023-09-20 00:04:26.457 INFO: Epoch 72: loss=0.0024, MAE_E_per_atom=32.8 meV, MAE_F=75.7 meV / A
2023-09-20 04:13:19.594 INFO: Epoch 74: loss=0.0015, MAE_E_per_atom=32.3 meV, MAE_F=74.6 meV / A
2023-09-20 04:13:19.634 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-74
2023-09-20 04:13:19.778 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-74/pytorch_model.bin
2023-09-20 04:13:20.169 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-74/optimizer.bin
2023-09-20 04:13:20.170 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-74/random_states_0.pkl
2023-09-20 08:24:28.895 INFO: Epoch 76: loss=0.0016, MAE_E_per_atom=32.2 meV, MAE_F=74.9 meV / A
2023-09-20 12:41:02.570 INFO: Epoch 78: loss=0.0016, MAE_E_per_atom=32.2 meV, MAE_F=74.8 meV / A
2023-09-20 16:58:58.001 INFO: Epoch 80: loss=0.0019, MAE_E_per_atom=31.5 meV, MAE_F=73.4 meV / A
2023-09-20 21:20:01.810 INFO: Epoch 82: loss=0.0020, MAE_E_per_atom=31.8 meV, MAE_F=73.9 meV / A
2023-09-21 01:44:48.011 INFO: Epoch 84: loss=0.0022, MAE_E_per_atom=31.6 meV, MAE_F=73.8 meV / A
2023-09-21 06:14:40.716 INFO: Epoch 86: loss=0.0017, MAE_E_per_atom=31.3 meV, MAE_F=72.8 meV / A
2023-09-21 10:49:52.878 INFO: Epoch 88: loss=0.0019, MAE_E_per_atom=31.4 meV, MAE_F=73.5 meV / A
2023-09-21 15:29:51.548 INFO: Epoch 90: loss=0.0015, MAE_E_per_atom=30.9 meV, MAE_F=72.7 meV / A
2023-09-21 15:29:51.625 INFO: Saving current state to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-90
2023-09-21 15:29:51.842 INFO: Model weights saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-90/pytorch_model.bin
2023-09-21 15:29:52.179 INFO: Optimizer state saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-90/optimizer.bin
2023-09-21 15:29:52.180 INFO: Random states saved in data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-90/random_states_0.pkl
2023-09-21 20:20:31.686 INFO: Epoch 92: loss=0.0018, MAE_E_per_atom=30.7 meV, MAE_F=72.4 meV / A
2023-09-22 01:15:30.168 INFO: Epoch 94: loss=0.0015, MAE_E_per_atom=30.9 meV, MAE_F=71.9 meV / A
2023-09-22 06:16:09.024 INFO: Epoch 96: loss=0.0017, MAE_E_per_atom=36.4 meV, MAE_F=81.3 meV / A
2023-09-22 11:26:00.341 INFO: Epoch 98: loss=0.0018, MAE_E_per_atom=32.1 meV, MAE_F=74.8 meV / A
2023-09-22 13:57:10.542 INFO: Training complete
2023-09-22 13:57:10.542 INFO: Computing metrics for training, validation, and test sets
2023-09-22 13:57:10.543 INFO: Loading states from data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42_epoch-90
2023-09-22 13:57:10.622 INFO: All model weights loaded successfully
2023-09-22 13:57:10.823 INFO: All optimizer states loaded successfully
2023-09-22 13:57:10.823 INFO: All scheduler states loaded successfully
2023-09-22 13:57:10.824 INFO: All random states loaded successfully
2023-09-22 13:57:10.824 INFO: Loading in 0 custom states
2023-09-22 13:57:10.824 INFO: Loaded model from epoch 90
2023-09-22 13:57:10.824 INFO: Evaluating train ...
2023-09-22 15:10:11.894 INFO: Evaluating valid ...
2023-09-22 15:25:16.732 INFO: 
+-------------+--------------------+-----------------+------------------+
| config_type | MAE E / meV / atom | MAE F / meV / A | relative F MAE % |
+-------------+--------------------+-----------------+------------------+
|    train    |        30.5        |       71.6      |      45.27       |
|    valid    |        30.9        |       72.7      |      47.17       |
+-------------+--------------------+-----------------+------------------+
2023-09-22 15:25:16.734 INFO: Saving model to data-train-result/checkpoints/MACE_MPtrj_2022.9_run-42.model
2023-09-22 15:25:17.079 INFO: Done
